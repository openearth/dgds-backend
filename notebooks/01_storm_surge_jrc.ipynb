{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41cc070c",
   "metadata": {},
   "source": [
    "# 01 - Storm Surge Dataset JRC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c270d3",
   "metadata": {},
   "source": [
    "This script performs the following tasks:\n",
    "1. [Auth] writes data to Zarr files (cloud-native file format) (AUTh)\n",
    "3. [Deltares] checks and creates a geoJSON from Zarr data (required for the Front-End)\n",
    "2. [Deltares] uploads the Zarr to a Google Cloud Storage (GCS) bucket \n",
    "4. [Deltares] uploads the geoJSON to Mapbox \n",
    "5. [Deltares] update the STAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee2343",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- make consistent with cf conventions (AUTh?)\n",
    "- bold names in Zarr due to a dimension index (maybe this should be changed..)\n",
    "- come up with checks for Zarr file before continueing to create a geoJSON\n",
    "- multiple variables in generation (and the arbitrary order of it?!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81edf748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Optional; code formatter, installed as jupyter lab extension\\n#%load_ext lab_black\\n# Optional; code formatter, installed as jupyter notebook extension\\n%load_ext nb_black\\n\\n# imports\\nimport geojson\\nimport netCDF4 as nc\\nimport os\\nimport pathlib\\nimport sys\\nimport platform\\nimport xarray as xr\\nimport pandas as pd\\nimport zarr\\nimport subprocess\\nimport warnings\\nimport pystac\\nfrom google.cloud import storage\\nfrom dotenv import dotenv_values\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# make root directories importable by appending root to path\\ncwd = pathlib.Path().resolve()\\nsys.path.append(os.path.dirname(cwd))\\n\\n# OS independent path configurations\\nif platform.system() == \\\"Windows\\\":\\n    root = pathlib.Path(\\\"P:/\\\")\\nelse:  # linux or other\\n    root = pathlib.Path(\\\"/p/\\\")\\n# root = pathlib.Path().home().root\\ncoclico_data_dir = pathlib.Path(root, \\\"11205479-coclico\\\", \\\"data\\\")\";\n",
       "                var nbb_formatted_code = \"# Optional; code formatter, installed as jupyter lab extension\\n#%load_ext lab_black\\n# Optional; code formatter, installed as jupyter notebook extension\\n%load_ext nb_black\\n\\n# imports\\nimport geojson\\nimport netCDF4 as nc\\nimport os\\nimport pathlib\\nimport sys\\nimport platform\\nimport xarray as xr\\nimport pandas as pd\\nimport zarr\\nimport subprocess\\nimport warnings\\nimport pystac\\nfrom google.cloud import storage\\nfrom dotenv import dotenv_values\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# make root directories importable by appending root to path\\ncwd = pathlib.Path().resolve()\\nsys.path.append(os.path.dirname(cwd))\\n\\n# OS independent path configurations\\nif platform.system() == \\\"Windows\\\":\\n    root = pathlib.Path(\\\"P:/\\\")\\nelse:  # linux or other\\n    root = pathlib.Path(\\\"/p/\\\")\\n# root = pathlib.Path().home().root\\ncoclico_data_dir = pathlib.Path(root, \\\"11205479-coclico\\\", \\\"data\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional; code formatter, installed as jupyter lab extension\n",
    "#%load_ext lab_black\n",
    "# Optional; code formatter, installed as jupyter notebook extension\n",
    "%load_ext nb_black\n",
    "\n",
    "# imports\n",
    "import geojson\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import platform\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import subprocess\n",
    "import warnings\n",
    "import pystac\n",
    "from google.cloud import storage\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# make root directories importable by appending root to path\n",
    "cwd = pathlib.Path().resolve()\n",
    "sys.path.append(os.path.dirname(cwd))\n",
    "\n",
    "# OS independent path configurations\n",
    "if platform.system() == \"Windows\":\n",
    "    root = pathlib.Path(\"P:/\")\n",
    "else:  # linux or other\n",
    "    root = pathlib.Path(\"/p/\")\n",
    "# root = pathlib.Path().home().root\n",
    "coclico_data_dir = pathlib.Path(root, \"11205479-coclico\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b081e572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# paths to the dataset, manual input\\ndataset_dir = coclico_data_dir.joinpath(\\\"01_storm_surge_jrc\\\")\\ndataset_historical_path = dataset_dir.joinpath(\\\"CoastAlRisk_Europe_EESSL_Historical.nc\\\")\\ndataset_rcp45_path = dataset_dir.joinpath(\\\"CoastAlRisk_Europe_EESSL_RCP45.nc\\\")\\ndataset_rcp85_path = dataset_dir.joinpath(\\\"CoastAlRisk_Europe_EESSL_RCP85.nc\\\")\\ndataset_out_file = \\\"CoastAlRisk_Europe_EESSL\\\"\\n\\n# GCS and mapbox private access keys\\nGCS_token = coclico_data_dir.joinpath(\\n    \\\"google_credentials.json\\\"\\n)  # path name (including json file name)\\nconfig = dotenv_values(\\\".env\\\")\\nmapbox_token = config[\\\"MAPBOX_TOKEN\\\"] # mapbox private key\";\n",
       "                var nbb_formatted_code = \"# paths to the dataset, manual input\\ndataset_dir = coclico_data_dir.joinpath(\\\"01_storm_surge_jrc\\\")\\ndataset_historical_path = dataset_dir.joinpath(\\\"CoastAlRisk_Europe_EESSL_Historical.nc\\\")\\ndataset_rcp45_path = dataset_dir.joinpath(\\\"CoastAlRisk_Europe_EESSL_RCP45.nc\\\")\\ndataset_rcp85_path = dataset_dir.joinpath(\\\"CoastAlRisk_Europe_EESSL_RCP85.nc\\\")\\ndataset_out_file = \\\"CoastAlRisk_Europe_EESSL\\\"\\n\\n# GCS and mapbox private access keys\\nGCS_token = coclico_data_dir.joinpath(\\n    \\\"google_credentials.json\\\"\\n)  # path name (including json file name)\\nconfig = dotenv_values(\\\".env\\\")\\nmapbox_token = config[\\\"MAPBOX_TOKEN\\\"]  # mapbox private key\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# paths to the dataset, manual input\n",
    "dataset_dir = coclico_data_dir.joinpath(\"01_storm_surge_jrc\")\n",
    "dataset_historical_path = dataset_dir.joinpath(\"CoastAlRisk_Europe_EESSL_Historical.nc\")\n",
    "dataset_rcp45_path = dataset_dir.joinpath(\"CoastAlRisk_Europe_EESSL_RCP45.nc\")\n",
    "dataset_rcp85_path = dataset_dir.joinpath(\"CoastAlRisk_Europe_EESSL_RCP85.nc\")\n",
    "dataset_out_file = \"CoastAlRisk_Europe_EESSL\"\n",
    "\n",
    "# GCS and mapbox private access keys\n",
    "GCS_token = coclico_data_dir.joinpath(\n",
    "    \"google_credentials.json\"\n",
    ")  # path name (including json file name)\n",
    "config = dotenv_values(\".env\")\n",
    "mapbox_token = config[\"MAPBOX_TOKEN\"]  # mapbox private key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde6f94",
   "metadata": {},
   "source": [
    "# 1. write data to Zarr files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d3358af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"# open datasets\\ndataset_historical = xr.open_dataset(dataset_historical_path)\\ndataset_45rcp = xr.open_dataset(dataset_rcp45_path)\\ndataset_85rcp = xr.open_dataset(dataset_rcp85_path)\\n\\n# check original dataset\\n# dataset_historical\";\n",
       "                var nbb_formatted_code = \"# open datasets\\ndataset_historical = xr.open_dataset(dataset_historical_path)\\ndataset_45rcp = xr.open_dataset(dataset_rcp45_path)\\ndataset_85rcp = xr.open_dataset(dataset_rcp85_path)\\n\\n# check original dataset\\n# dataset_historical\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open datasets\n",
    "dataset_historical = xr.open_dataset(dataset_historical_path)\n",
    "dataset_45rcp = xr.open_dataset(dataset_rcp45_path)\n",
    "dataset_85rcp = xr.open_dataset(dataset_rcp85_path)\n",
    "\n",
    "# check original dataset\n",
    "# dataset_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7185660b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 105;\n",
       "                var nbb_unformatted_code = \"# rename dimension names\\ndataset_historical = dataset_historical.rename_dims({\\\"row\\\": \\\"stations\\\", \\\"col\\\": \\\"rp\\\"})\\ndataset_45rcp = dataset_45rcp.rename_dims({\\\"row\\\": \\\"stations\\\", \\\"col\\\": \\\"rp\\\"})\\ndataset_85rcp = dataset_85rcp.rename_dims({\\\"row\\\": \\\"stations\\\", \\\"col\\\": \\\"rp\\\"})\\n\\n# rename variables, if necessary\\ndataset_historical = dataset_historical.rename_vars({\\\"RP\\\": \\\"rp\\\"})\\ndataset_45rcp = dataset_45rcp.rename_vars({\\\"RP\\\": \\\"rp\\\"})\\ndataset_85rcp = dataset_85rcp.rename_vars({\\\"RP\\\": \\\"rp\\\"})\\n\\n# set some data variables to coordinates to avoid duplication of dimensions in later stage\\ndataset_historical = dataset_historical.set_coords([\\\"longitude\\\", \\\"latitude\\\", \\\"rp\\\"])\\ndataset_45rcp = dataset_45rcp.set_coords([\\\"longitude\\\", \\\"latitude\\\", \\\"rp\\\"])\\ndataset_85rcp = dataset_85rcp.set_coords([\\\"longitude\\\", \\\"latitude\\\", \\\"rp\\\"])\";\n",
       "                var nbb_formatted_code = \"# rename dimension names\\ndataset_historical = dataset_historical.rename_dims({\\\"row\\\": \\\"stations\\\", \\\"col\\\": \\\"rp\\\"})\\ndataset_45rcp = dataset_45rcp.rename_dims({\\\"row\\\": \\\"stations\\\", \\\"col\\\": \\\"rp\\\"})\\ndataset_85rcp = dataset_85rcp.rename_dims({\\\"row\\\": \\\"stations\\\", \\\"col\\\": \\\"rp\\\"})\\n\\n# rename variables, if necessary\\ndataset_historical = dataset_historical.rename_vars({\\\"RP\\\": \\\"rp\\\"})\\ndataset_45rcp = dataset_45rcp.rename_vars({\\\"RP\\\": \\\"rp\\\"})\\ndataset_85rcp = dataset_85rcp.rename_vars({\\\"RP\\\": \\\"rp\\\"})\\n\\n# set some data variables to coordinates to avoid duplication of dimensions in later stage\\ndataset_historical = dataset_historical.set_coords([\\\"longitude\\\", \\\"latitude\\\", \\\"rp\\\"])\\ndataset_45rcp = dataset_45rcp.set_coords([\\\"longitude\\\", \\\"latitude\\\", \\\"rp\\\"])\\ndataset_85rcp = dataset_85rcp.set_coords([\\\"longitude\\\", \\\"latitude\\\", \\\"rp\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rename dimension names\n",
    "dataset_historical = dataset_historical.rename_dims({\"row\": \"stations\", \"col\": \"rp\"})\n",
    "dataset_45rcp = dataset_45rcp.rename_dims({\"row\": \"stations\", \"col\": \"rp\"})\n",
    "dataset_85rcp = dataset_85rcp.rename_dims({\"row\": \"stations\", \"col\": \"rp\"})\n",
    "\n",
    "# rename variables, if necessary\n",
    "dataset_historical = dataset_historical.rename_vars({\"RP\": \"rp\"})\n",
    "dataset_45rcp = dataset_45rcp.rename_vars({\"RP\": \"rp\"})\n",
    "dataset_85rcp = dataset_85rcp.rename_vars({\"RP\": \"rp\"})\n",
    "\n",
    "# set some data variables to coordinates to avoid duplication of dimensions in later stage\n",
    "dataset_historical = dataset_historical.set_coords([\"longitude\", \"latitude\", \"rp\"])\n",
    "dataset_45rcp = dataset_45rcp.set_coords([\"longitude\", \"latitude\", \"rp\"])\n",
    "dataset_85rcp = dataset_85rcp.set_coords([\"longitude\", \"latitude\", \"rp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "df43b59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 106;\n",
       "                var nbb_unformatted_code = \"# concat datasets along new dimension with index values and name derived from pandas index object, if necessary\\ndataset = xr.concat(\\n    [dataset_historical, dataset_45rcp, dataset_85rcp],\\n    pd.Index([\\\"historical\\\", \\\"rcp45\\\", \\\"rcp85\\\"], name=\\\"scenario\\\"),\\n)\";\n",
       "                var nbb_formatted_code = \"# concat datasets along new dimension with index values and name derived from pandas index object, if necessary\\ndataset = xr.concat(\\n    [dataset_historical, dataset_45rcp, dataset_85rcp],\\n    pd.Index([\\\"historical\\\", \\\"rcp45\\\", \\\"rcp85\\\"], name=\\\"scenario\\\"),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concat datasets along new dimension with index values and name derived from pandas index object, if necessary\n",
    "dataset = xr.concat(\n",
    "    [dataset_historical, dataset_45rcp, dataset_85rcp],\n",
    "    pd.Index([\"historical\", \"rcp45\", \"rcp85\"], name=\"scenario\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "38b92a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"# re-order shape of the data variables\\ndataset = dataset.transpose(\\\"scenario\\\", \\\"stations\\\", \\\"rp\\\")\";\n",
       "                var nbb_formatted_code = \"# re-order shape of the data variables\\ndataset = dataset.transpose(\\\"scenario\\\", \\\"stations\\\", \\\"rp\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-order shape of the data variables\n",
    "dataset = dataset.transpose(\"scenario\", \"stations\", \"rp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7ae43275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (stations: 2242, scenario: 3, rp: 8)\n",
       "Coordinates:\n",
       "    longitude  (stations) float64 -0.1 -0.1 -0.1 -0.1 -0.3 ... 9.9 9.9 9.9 9.9\n",
       "    latitude   (stations) float64 36.1 39.3 49.7 54.3 ... 57.7 58.7 64.5 64.7\n",
       "  * rp         (rp) float32 5.0 10.0 20.0 50.0 100.0 200.0 500.0 1e+03\n",
       "  * scenario   (scenario) object &#x27;historical&#x27; &#x27;rcp45&#x27; &#x27;rcp85&#x27;\n",
       "Dimensions without coordinates: stations\n",
       "Data variables:\n",
       "    ssl        (scenario, stations, rp) float64 1.024 1.051 ... 2.712 2.805\n",
       "Attributes:\n",
       "    title:            European extreme storm surge level\n",
       "    Institution:      Joint European Research Center, Institute of Environmen...\n",
       "    Project Name:     Prototype of a first Global Integrated Coastal Impact-b...\n",
       "    Project Acronym:  CoastAlRisk\n",
       "    reference:        Vousdoukas MI, Voukouvalas E, Annunziato A, Giardino A,...\n",
       "    email:            michail.vousdoukas@ec.europa.eu\n",
       "    version:          1.0\n",
       "    terms_for_use:    European Union, 1995-2015.\\nReuse is authorised, provid...\n",
       "    disclaimer:       Unless the following would not be permitted or valid un...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-be32dfad-fe7c-42c9-9788-52592db5ebfc' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-be32dfad-fe7c-42c9-9788-52592db5ebfc' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span>stations</span>: 2242</li><li><span class='xr-has-index'>scenario</span>: 3</li><li><span class='xr-has-index'>rp</span>: 8</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-374a338b-30a8-4d2c-98b1-c7a25fbc9079' class='xr-section-summary-in' type='checkbox'  checked><label for='section-374a338b-30a8-4d2c-98b1-c7a25fbc9079' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>longitude</span></div><div class='xr-var-dims'>(stations)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-0.1 -0.1 -0.1 -0.1 ... 9.9 9.9 9.9</div><input id='attrs-b6cf514b-140d-4f48-bbeb-d7407a3da8d2' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b6cf514b-140d-4f48-bbeb-d7407a3da8d2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3db4c056-0a9b-4c6c-a16e-ef5b18460fef' class='xr-var-data-in' type='checkbox'><label for='data-3db4c056-0a9b-4c6c-a16e-ef5b18460fef' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>standard_name :</span></dt><dd>longitude</dd></dl></div><div class='xr-var-data'><pre>array([-0.1, -0.1, -0.1, ...,  9.9,  9.9,  9.9])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>latitude</span></div><div class='xr-var-dims'>(stations)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>36.1 39.3 49.7 ... 58.7 64.5 64.7</div><input id='attrs-d1ef006c-6b71-42f2-83b7-b4137be2083b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-d1ef006c-6b71-42f2-83b7-b4137be2083b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1ea8d225-daf2-48c1-a36b-2903e44195c3' class='xr-var-data-in' type='checkbox'><label for='data-1ea8d225-daf2-48c1-a36b-2903e44195c3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>standard_name :</span></dt><dd>latitude</dd></dl></div><div class='xr-var-data'><pre>array([36.1, 39.3, 49.7, ..., 58.7, 64.5, 64.7])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>rp</span></div><div class='xr-var-dims'>(rp)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>5.0 10.0 20.0 ... 200.0 500.0 1e+03</div><input id='attrs-aa44899c-0c61-4115-a151-683462c269b8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-aa44899c-0c61-4115-a151-683462c269b8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-99792de3-7aed-4bb6-9cfa-b8323968b02f' class='xr-var-data-in' type='checkbox'><label for='data-99792de3-7aed-4bb6-9cfa-b8323968b02f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>return period</dd><dt><span>units :</span></dt><dd>yr</dd><dt><span>Contents :</span></dt><dd>The RPs have been estimated following the Peak Over Threshold Method (see reference below)</dd><dt><span>Starting date :</span></dt><dd>01-Dec-1969</dd><dt><span>End date :</span></dt><dd>30-Nov-2004 21:00:00</dd></dl></div><div class='xr-var-data'><pre>array([   5.,   10.,   20.,   50.,  100.,  200.,  500., 1000.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>scenario</span></div><div class='xr-var-dims'>(scenario)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;historical&#x27; &#x27;rcp45&#x27; &#x27;rcp85&#x27;</div><input id='attrs-dadacdfc-ac7e-4109-bf5f-8fb5a5c2312b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-dadacdfc-ac7e-4109-bf5f-8fb5a5c2312b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4059061c-c1a8-408a-9c4d-5cd4c9344405' class='xr-var-data-in' type='checkbox'><label for='data-4059061c-c1a8-408a-9c4d-5cd4c9344405' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;historical&#x27;, &#x27;rcp45&#x27;, &#x27;rcp85&#x27;], dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c51c4bb7-dec9-4f79-b262-50beb0539921' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c51c4bb7-dec9-4f79-b262-50beb0539921' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>ssl</span></div><div class='xr-var-dims'>(scenario, stations, rp)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.024 1.051 1.078 ... 2.712 2.805</div><input id='attrs-2c5bf150-bde5-4ffb-ad58-a446ee2fa5f6' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2c5bf150-bde5-4ffb-ad58-a446ee2fa5f6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ae509072-0b87-4feb-b99a-e6a05ccf998f' class='xr-var-data-in' type='checkbox'><label for='data-ae509072-0b87-4feb-b99a-e6a05ccf998f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>storm surge level</dd><dt><span>units :</span></dt><dd>m</dd></dl></div><div class='xr-var-data'><pre>array([[[1.02407, 1.0509 , 1.0778 , ..., 1.16939, 1.20762, 1.23753],\n",
       "        [1.24336, 1.28508, 1.32805, ..., 1.4857 , 1.55811, 1.61812],\n",
       "        [1.95   , 2.08892, 2.20901, ..., 2.51257, 2.60544, 2.66859],\n",
       "        ...,\n",
       "        [2.05624, 2.20418, 2.33512, ..., 2.67975, 2.78853, 2.86284],\n",
       "        [1.86446, 2.02245, 2.16554, ..., 2.55166, 2.67389, 2.7566 ],\n",
       "        [1.87579, 2.02328, 2.1549 , ..., 2.49943, 2.60478, 2.67487]],\n",
       "\n",
       "       [[1.03165, 1.05851, 1.08478, ..., 1.16899, 1.20167, 1.22622],\n",
       "        [1.23326, 1.27602, 1.32215, ..., 1.50603, 1.59589, 1.67189],\n",
       "        [1.97503, 2.12185, 2.25063, ..., 2.58303, 2.68587, 2.75567],\n",
       "        ...,\n",
       "        [2.11645, 2.25912, 2.38164, ..., 2.68137, 2.7671 , 2.82265],\n",
       "        [1.91546, 2.07808, 2.22304, ..., 2.60134, 2.71649, 2.79291],\n",
       "        [1.9071 , 2.05876, 2.19542, ..., 2.56052, 2.67487, 2.75187]],\n",
       "\n",
       "       [[1.03412, 1.06436, 1.09628, ..., 1.21896, 1.27761, 1.32699],\n",
       "        [1.22974, 1.2753 , 1.32831, ..., 1.5973 , 1.77785, 1.96619],\n",
       "        [1.985  , 2.12493, 2.24118, ..., 2.50843, 2.57984, 2.62478],\n",
       "        ...,\n",
       "        [2.10311, 2.24885, 2.37682, ..., 2.70514, 2.80472, 2.87116],\n",
       "        [1.92381, 2.08563, 2.23729, ..., 2.67873, 2.83175, 2.94024],\n",
       "        [1.89731, 2.04812, 2.18738, ..., 2.58059, 2.7125 , 2.80462]]])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-01c207c8-6ffc-4cc3-ba1b-abad383bbb43' class='xr-section-summary-in' type='checkbox'  checked><label for='section-01c207c8-6ffc-4cc3-ba1b-abad383bbb43' class='xr-section-summary' >Attributes: <span>(9)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>title :</span></dt><dd>European extreme storm surge level</dd><dt><span>Institution :</span></dt><dd>Joint European Research Center, Institute of Environment and Sustainability, Via Enrico Fermi 2749, I-21027-Ispra</dd><dt><span>Project Name :</span></dt><dd>Prototype of a first Global Integrated Coastal Impact-based Flood Alert and Risk Assessment Tool</dd><dt><span>Project Acronym :</span></dt><dd>CoastAlRisk</dd><dt><span>reference :</span></dt><dd>Vousdoukas MI, Voukouvalas E, Annunziato A, Giardino A, Feyen L. Projections of extreme storm surge levels along Europe. Clim Dyn. February 2016. doi:10.1007/s00382-016-3019-5</dd><dt><span>email :</span></dt><dd>michail.vousdoukas@ec.europa.eu</dd><dt><span>version :</span></dt><dd>1.0</dd><dt><span>terms_for_use :</span></dt><dd>European Union, 1995-2015.\n",
       "Reuse is authorised, provided the source is acknowledged. The reuse policy of the European Commission is implemented by a Decision of 12 December 2011.</dd><dt><span>disclaimer :</span></dt><dd>Unless the following would not be permitted or valid under applicable law, the following applies to the data/information provided by the JRC:\n",
       "\n",
       "1. The JRC data are provided &quot;as is&quot; and &quot;as available&quot; without warranty of any kind, either express or implied, including, but not limited to, any implied warranty against infringement of third parties&#x27; property rights, or merchantability, integration, absence of latent or other defects, satisfactory quality and fitness for a particular purpose. The JRC data do not constitute professional or legal advice (if you need specific advice, you should always consult a suitably qualified professional).\n",
       "2. The JRC has no obligation to provide technical support or remedies for the data. The JRC does not represent or warrant that the data will be error free or uninterrupted, or that all non-conformities can or will be corrected, or that any data are accurate or complete, or that they are of a satisfactory technical or scientific quality.\n",
       "3. The JRC or as the case may be the European Commission shall not be held liable for any direct or indirect, incidental, consequential or other damages, including but not limited to the loss of data, loss of profits, or any other financial loss arising from the use of the JRC data, or inability to use them, even if the JRC is notified of the possibility of such damages.</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (stations: 2242, scenario: 3, rp: 8)\n",
       "Coordinates:\n",
       "    longitude  (stations) float64 -0.1 -0.1 -0.1 -0.1 -0.3 ... 9.9 9.9 9.9 9.9\n",
       "    latitude   (stations) float64 36.1 39.3 49.7 54.3 ... 57.7 58.7 64.5 64.7\n",
       "  * rp         (rp) float32 5.0 10.0 20.0 50.0 100.0 200.0 500.0 1e+03\n",
       "  * scenario   (scenario) object 'historical' 'rcp45' 'rcp85'\n",
       "Dimensions without coordinates: stations\n",
       "Data variables:\n",
       "    ssl        (scenario, stations, rp) float64 1.024 1.051 ... 2.712 2.805\n",
       "Attributes:\n",
       "    title:            European extreme storm surge level\n",
       "    Institution:      Joint European Research Center, Institute of Environmen...\n",
       "    Project Name:     Prototype of a first Global Integrated Coastal Impact-b...\n",
       "    Project Acronym:  CoastAlRisk\n",
       "    reference:        Vousdoukas MI, Voukouvalas E, Annunziato A, Giardino A,...\n",
       "    email:            michail.vousdoukas@ec.europa.eu\n",
       "    version:          1.0\n",
       "    terms_for_use:    European Union, 1995-2015.\\nReuse is authorised, provid...\n",
       "    disclaimer:       Unless the following would not be permitted or valid un..."
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 110;\n",
       "                var nbb_unformatted_code = \"# check the xarray dataset\\ndataset\";\n",
       "                var nbb_formatted_code = \"# check the xarray dataset\\ndataset\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the xarray dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "12a88562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x210cb728580>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 111;\n",
       "                var nbb_unformatted_code = \"# export to zarr in write mode (to overwrite iff exists)\\ndataset.to_zarr(dataset_dir.joinpath(\\\"%s.zarr\\\" % dataset_out_file), mode=\\\"w\\\")\";\n",
       "                var nbb_formatted_code = \"# export to zarr in write mode (to overwrite iff exists)\\ndataset.to_zarr(dataset_dir.joinpath(\\\"%s.zarr\\\" % dataset_out_file), mode=\\\"w\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export to zarr in write mode (to overwrite iff exists)\n",
    "dataset.to_zarr(dataset_dir.joinpath(\"%s.zarr\" % dataset_out_file), mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21989f",
   "metadata": {},
   "source": [
    "# 2. check and create geoJSON from Zarr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7e6a0735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 112;\n",
       "                var nbb_unformatted_code = \"# locally stored Zarr\\ndataset = xr.open_dataset(dataset_dir.joinpath(\\\"%s.zarr\\\" % dataset_out_file))\";\n",
       "                var nbb_formatted_code = \"# locally stored Zarr\\ndataset = xr.open_dataset(dataset_dir.joinpath(\\\"%s.zarr\\\" % dataset_out_file))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# locally stored Zarr\n",
    "dataset = xr.open_dataset(dataset_dir.joinpath(\"%s.zarr\" % dataset_out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fd25668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"# do checks (to be decided upon)\";\n",
       "                var nbb_formatted_code = \"# do checks (to be decided upon)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do checks (to be decided upon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45a9f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc2d27c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12572/3558510867.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdimvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12572/3558510867.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdimvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 120;\n",
       "                var nbb_unformatted_code = \"dimvals = {k: v.values for k, v in dataset.items() if v.values}\";\n",
       "                var nbb_formatted_code = \"dimvals = {k: v.values for k, v in dataset.items() if v.values}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dimvals = {k: v.values for k, v in cube_dimensions.items() if v.values}\n",
    "\n",
    "# Add children\n",
    "for values in product(*dimvals.values()):\n",
    "    # TODO Improve key gen and align with geojson generation\n",
    "    key = \"-\".join(\n",
    "        map(lambda x: \"-\".join(x), zip(dimvals.keys(), map(str, values)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "db782cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['historical', 'rcp45', 'rcp85'], dtype=object),\n",
       " array([   5.,   10.,   20.,   50.,  100.,  200.,  500., 1000.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 138;\n",
       "                var nbb_unformatted_code = \"var_dims_idx\\nvar_dims_ids\\nvar_dims_val\";\n",
       "                var nbb_formatted_code = \"var_dims_idx\\nvar_dims_ids\\nvar_dims_val\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_dims_idx\n",
    "var_dims_ids\n",
    "var_dims_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d9b33fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['historical_5.0', 'historical_10.0', 'historical_20.0', 'historical_50.0', 'historical_100.0', 'historical_200.0', 'historical_500.0', 'historical_1000.0', 'rcp45_5.0', 'rcp45_10.0', 'rcp45_20.0', 'rcp45_50.0', 'rcp45_100.0', 'rcp45_200.0', 'rcp45_500.0', 'rcp45_1000.0', 'rcp85_5.0', 'rcp85_10.0', 'rcp85_20.0', 'rcp85_50.0', 'rcp85_100.0', 'rcp85_200.0', 'rcp85_500.0', 'rcp85_1000.0']\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 176;\n",
       "                var nbb_unformatted_code = \"from itertools import product\\n\\nlist3 = [f\\\"{a}_{b}\\\" for a, b in product(var_dims_val[0], var_dims_val[1])]\\nprint(list3)\";\n",
       "                var nbb_formatted_code = \"from itertools import product\\n\\nlist3 = [f\\\"{a}_{b}\\\" for a, b in product(var_dims_val[0], var_dims_val[1])]\\nprint(list3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "list3 = [f\"{a}_{b}\" for a, b in product(var_dims_val[0], var_dims_val[1])]\n",
    "print(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6786b54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 scenario ['historical' 'rcp45' 'rcp85']\n",
      "1 2 rp [   5.   10.   20.   50.  100.  200.  500. 1000.]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 154;\n",
       "                var nbb_unformatted_code = \"# write geoJSON (generic)\\n\\n# list(dataset.dims)\\n# write data to single flattened GeoJSON - Mapbox styling could use this\\nfor var in dataset.keys():  # get variable\\n    dims = list(dataset[\\\"%s\\\" % var].dims)\\n    var_dims_idx = []\\n    var_dims_ids = []\\n    var_dims_val = []\\n    for idv, name in enumerate(dims):  # get dimensions of variable\\n        if name != \\\"stations\\\":  # assumes stations is present and independent\\n            var_dims_idx.append(idv)\\n            var_dims_ids.append(name)\\n            var_dims_val.append(dataset[\\\"%s\\\" % name][:].values)\\n\\n    features = []\\n    for j, (lon, lat) in enumerate(\\n        zip(dataset[\\\"longitude\\\"][:].values, dataset[\\\"latitude\\\"][:].values)\\n    ):  # assumes longitude and latitude are present and independent\\n        point = geojson.Point((float(lon), float(lat)))\\n        feature = geojson.Feature(geometry=point)\\n        feature[\\\"properties\\\"][\\\"locationId\\\"] = j\\n\\n        for idv, (a, b, c) in enumerate(zip(var_dims_idx, var_dims_ids, var_dims_val)):\\n            print(idv, a, b, c)\\n        break\\n#            print(idv, a)\\n#            feature[\\\"properties\\\"][\\\"%s_%s_%s_%s\\\" % int(a)] = str(b)\\n#            # for b in a:\\n#\\n#            break\\n#        break\\n#\\n#        for a, b in zip(rps, dataset[\\\"%s\\\"%var][idx, j, :].values):\\n#    #        feature[\\\"properties\\\"][\\\"rp_%s\\\" % int(a)] = str(b)\\n#    #    features.append(feature)\";\n",
       "                var nbb_formatted_code = \"# write geoJSON (generic)\\n\\n# list(dataset.dims)\\n# write data to single flattened GeoJSON - Mapbox styling could use this\\nfor var in dataset.keys():  # get variable\\n    dims = list(dataset[\\\"%s\\\" % var].dims)\\n    var_dims_idx = []\\n    var_dims_ids = []\\n    var_dims_val = []\\n    for idv, name in enumerate(dims):  # get dimensions of variable\\n        if name != \\\"stations\\\":  # assumes stations is present and independent\\n            var_dims_idx.append(idv)\\n            var_dims_ids.append(name)\\n            var_dims_val.append(dataset[\\\"%s\\\" % name][:].values)\\n\\n    features = []\\n    for j, (lon, lat) in enumerate(\\n        zip(dataset[\\\"longitude\\\"][:].values, dataset[\\\"latitude\\\"][:].values)\\n    ):  # assumes longitude and latitude are present and independent\\n        point = geojson.Point((float(lon), float(lat)))\\n        feature = geojson.Feature(geometry=point)\\n        feature[\\\"properties\\\"][\\\"locationId\\\"] = j\\n\\n        for idv, (a, b, c) in enumerate(zip(var_dims_idx, var_dims_ids, var_dims_val)):\\n            print(idv, a, b, c)\\n        break\\n#            print(idv, a)\\n#            feature[\\\"properties\\\"][\\\"%s_%s_%s_%s\\\" % int(a)] = str(b)\\n#            # for b in a:\\n#\\n#            break\\n#        break\\n#\\n#        for a, b in zip(rps, dataset[\\\"%s\\\"%var][idx, j, :].values):\\n#    #        feature[\\\"properties\\\"][\\\"rp_%s\\\" % int(a)] = str(b)\\n#    #    features.append(feature)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write geoJSON (generic)\n",
    "\n",
    "# list(dataset.dims)\n",
    "# write data to single flattened GeoJSON - Mapbox styling could use this\n",
    "for var in dataset.keys():  # loop over variable\n",
    "    dims = list(dataset[\"%s\" % var].dims)\n",
    "    var_dims_idx = []\n",
    "    var_dims_ids = []\n",
    "    var_dims_val = []\n",
    "    for idv, name in enumerate(dims):  # loop over dimensions of variable\n",
    "        if name != \"stations\":  # assumes stations is present and independent\n",
    "            var_dims_idx.append(idv)\n",
    "            var_dims_ids.append(name)\n",
    "            var_dims_val.append(dataset[\"%s\" % name][:].values)\n",
    "            \n",
    "    # dot product of var_dims_val\n",
    "    \n",
    "\n",
    "    features = []\n",
    "    for j, (lon, lat) in enumerate(\n",
    "        zip(dataset[\"longitude\"][:].values, dataset[\"latitude\"][:].values)\n",
    "    ):  # assumes longitude and latitude are present and independent\n",
    "        point = geojson.Point((float(lon), float(lat)))\n",
    "        feature = geojson.Feature(geometry=point)\n",
    "        feature[\"properties\"][\"locationId\"] = j\n",
    "\n",
    "        for idv, (a, b, c) in enumerate(zip(var_dims_idx, var_dims_ids, var_dims_val)):\n",
    "            print(idv, a, b, c)\n",
    "        break\n",
    "#            print(idv, a)\n",
    "#            feature[\"properties\"][\"%s_%s_%s_%s\" % int(a)] = str(b)\n",
    "#            # for b in a:\n",
    "#\n",
    "#            break\n",
    "#        break\n",
    "#\n",
    "#        for a, b in zip(rps, dataset[\"%s\"%var][idx, j, :].values):\n",
    "#    #        feature[\"properties\"][\"rp_%s\" % int(a)] = str(b)\n",
    "#    #    features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "725f7f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 129;\n",
       "                var nbb_unformatted_code = \"# write geoJSON\\n\\n# filter out scenarios\\nds_list_name = []\\nfor idx, i in enumerate(dataset[\\\"scenario\\\"][:].values):\\n    ds_list_name.append(dataset_out_file + \\\"_\\\" + i)\\n\\n# write data to files (multiple value files - arrays) - Mapbox styling could be done with arrays\\nfor idx, name in enumerate(ds_list_name):\\n    rps = dataset[\\\"rp\\\"][:].values\\n\\n    features = []\\n    for j, (lon, lat) in enumerate(\\n        zip(dataset[\\\"longitude\\\"][:].values, dataset[\\\"latitude\\\"][:].values)\\n    ):\\n        point = geojson.Point((float(lon), float(lat)))\\n        feature = geojson.Feature(geometry=point)\\n        feature[\\\"properties\\\"][\\\"locationId\\\"] = j\\n        for a, b in zip(rps, dataset[\\\"ssl\\\"][idx, j, :].values):\\n            feature[\\\"properties\\\"][\\\"rp_%s\\\" % int(a)] = str(b)\\n        features.append(feature)\\n\\n    # store the features\\n    collection = geojson.FeatureCollection(features)\\n    with open(os.path.join(dataset_dir, \\\"platform\\\", r\\\"%s.geojson\\\" % name), \\\"w\\\") as f:\\n        geojson.dump(collection, f)\";\n",
       "                var nbb_formatted_code = \"# write geoJSON\\n\\n# filter out scenarios\\nds_list_name = []\\nfor idx, i in enumerate(dataset[\\\"scenario\\\"][:].values):\\n    ds_list_name.append(dataset_out_file + \\\"_\\\" + i)\\n\\n# write data to files (multiple value files - arrays) - Mapbox styling could be done with arrays\\nfor idx, name in enumerate(ds_list_name):\\n    rps = dataset[\\\"rp\\\"][:].values\\n\\n    features = []\\n    for j, (lon, lat) in enumerate(\\n        zip(dataset[\\\"longitude\\\"][:].values, dataset[\\\"latitude\\\"][:].values)\\n    ):\\n        point = geojson.Point((float(lon), float(lat)))\\n        feature = geojson.Feature(geometry=point)\\n        feature[\\\"properties\\\"][\\\"locationId\\\"] = j\\n        for a, b in zip(rps, dataset[\\\"ssl\\\"][idx, j, :].values):\\n            feature[\\\"properties\\\"][\\\"rp_%s\\\" % int(a)] = str(b)\\n        features.append(feature)\\n\\n    # store the features\\n    collection = geojson.FeatureCollection(features)\\n    with open(os.path.join(dataset_dir, \\\"platform\\\", r\\\"%s.geojson\\\" % name), \\\"w\\\") as f:\\n        geojson.dump(collection, f)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write geoJSON\n",
    "\n",
    "# filter out scenarios\n",
    "ds_list_name = []\n",
    "for idx, i in enumerate(dataset[\"scenario\"][:].values):\n",
    "    ds_list_name.append(dataset_out_file + \"_\" + i)\n",
    "\n",
    "# write data to files (multiple value files - arrays) - Mapbox styling could be done with arrays\n",
    "for idx, name in enumerate(ds_list_name):\n",
    "    rps = dataset[\"rp\"][:].values\n",
    "\n",
    "    features = []\n",
    "    for j, (lon, lat) in enumerate(\n",
    "        zip(dataset[\"longitude\"][:].values, dataset[\"latitude\"][:].values)\n",
    "    ):\n",
    "        point = geojson.Point((float(lon), float(lat)))\n",
    "        feature = geojson.Feature(geometry=point)\n",
    "        feature[\"properties\"][\"locationId\"] = j\n",
    "        for a, b in zip(rps, dataset[\"ssl\"][idx, j, :].values):\n",
    "            feature[\"properties\"][\"rp_%s\" % int(a)] = str(b)\n",
    "        features.append(feature)\n",
    "\n",
    "    # store the features\n",
    "    collection = geojson.FeatureCollection(features)\n",
    "    with open(os.path.join(dataset_dir, \"platform\", r\"%s.geojson\" % name), \"w\") as f:\n",
    "        geojson.dump(collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# copy current folder and generate.py.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23beac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geojson config ()\n",
    "\n",
    "    zarr_fn = \"gcs://dgds-data-public/coclico/CoastAlRisk_Europe_EESSL.zarr\"\n",
    "    mapbox_url, mapbox_source = \"https://\", \"adsasd\"\n",
    "    template = \"deltares-coclico-ssl\"\n",
    "    variable = \"elevation\"\n",
    "    datasetid = f\"deltares-coclico-{variable}\"\n",
    "    dimensions = [\"RP\", \"scenario\"]  # could be automatic\n",
    "\n",
    "# this needs to be aligned!! \n",
    "for values in product(*dimvals.values()):\n",
    "        # TODO Improve key gen and align with geojson generation\n",
    "        key = \"-\".join(\n",
    "            map(lambda x: \"-\".join(x), zip(dimvals.keys(), map(str, values)))\n",
    "        )\n",
    "        feature = gen_default_item(f\"{variable}-mapbox-{key}\")\n",
    "        feature.add_asset(\"mapbox\", gen_mapbox_asset(mapbox_url, mapbox_source))\n",
    "        feature.properties = gen_default_props(key=key)\n",
    "        for (k, v) in zip(dimvals.keys(), values):\n",
    "            feature.properties[k] = v\n",
    "        dataset.add_item(feature, strategy=layout)\n",
    "        feature.set_self_href(f\"../{variable}-mapbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85da0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "729c8858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"geometry\": {\"coordinates\": [-0.1, 49.7], \"type\": \"Point\"}, \"properties\": {\"locationId\": 2, \"rp_10\": \"2.12493\", \"rp_100\": \"2.44322\", \"rp_1000\": \"2.62478\", \"rp_20\": \"2.24118\", \"rp_200\": \"2.50843\", \"rp_5\": \"1.985\", \"rp_50\": \"2.36607\", \"rp_500\": \"2.57984\"}, \"type\": \"Feature\"}\n",
      "5.0 0.23 4.19\n",
      "10.0 0.24 4.21\n",
      "20.0 0.24 4.32\n",
      "50.0 0.24 4.71\n",
      "100.0 0.25 4.97\n",
      "200.0 0.25 5.19\n",
      "500.0 0.26 5.44\n",
      "1000.0 0.26 5.61\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"# check geojson\\n\\nwith open(os.path.join(eessl_dir, \\\"platform\\\", \\\"%s.geojson\\\" % ds_list_name[2])) as f:\\n    check = geojson.load(f)\\n\\nprint(check[\\\"features\\\"][2])\\n\\n# check the minima and maxima for the colormap boundaries\\nscenario = 0\\nfor idx, i in enumerate(rps):\\n    print(\\n        i,\\n        round(min(eessl[\\\"ssl\\\"][scenario, :, idx].values), 2),\\n        round(max(eessl[\\\"ssl\\\"][scenario, :, idx].values), 2),\\n    )\";\n",
       "                var nbb_formatted_code = \"# check geojson\\n\\nwith open(os.path.join(eessl_dir, \\\"platform\\\", \\\"%s.geojson\\\" % ds_list_name[2])) as f:\\n    check = geojson.load(f)\\n\\nprint(check[\\\"features\\\"][2])\\n\\n# check the minima and maxima for the colormap boundaries\\nscenario = 0\\nfor idx, i in enumerate(rps):\\n    print(\\n        i,\\n        round(min(eessl[\\\"ssl\\\"][scenario, :, idx].values), 2),\\n        round(max(eessl[\\\"ssl\\\"][scenario, :, idx].values), 2),\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check geojson\n",
    "\n",
    "with open(os.path.join(dataset_dir, \"platform\", \"%s.geojson\" % ds_list_name[2])) as f:\n",
    "    check = geojson.load(f)\n",
    "\n",
    "print(check[\"features\"][2])\n",
    "\n",
    "# check the minima and maxima for the colormap boundaries\n",
    "#scenario = 0\n",
    "#for idx, i in enumerate(rps):\n",
    "#    print(\n",
    "#        i,\n",
    "#        round(min(dataset[\"ssl\"][scenario, :, idx].values), 2),\n",
    "#        round(max(dataset[\"ssl\"][scenario, :, idx].values), 2),\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2ccc1",
   "metadata": {},
   "source": [
    "# 3. upload Zarr to GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5f94af33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder uploaded to GCS\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"# trial\\nos.environ[\\\"GOOGLE_APPLICATION_CREDENTIALS\\\"] = str(GCS_token)\\n\\nstorage_client = storage.Client()\\ndef upload_from_directory(directory_path, dest_bucket_name, dest_blob_name):\\n    rel_paths = directory_path.glob(\\\"**/*\\\")\\n    bucket = storage_client.bucket(dest_bucket_name)\\n    for local_file in rel_paths:\\n        remote_path = f'{dest_blob_name}/{\\\"/\\\".join(str(local_file).split(os.sep)[5:])}'\\n        if os.path.isfile(local_file):\\n            blob = bucket.blob(remote_path)\\n            blob.upload_from_filename(local_file)\\n\\n    # print status\\n    print(\\\"Folder uploaded to GCS\\\")\\n    \\ndirectory_path = eessl_dir.joinpath(\\\"%s.zarr\\\" % eessl_out_file)\\ndest_bucket_name = \\\"dgds-data-public\\\"\\ndest_blob_name = \\\"coclico/\\\" + eessl_out_file + \\\".zarr\\\"\\nfolder_upload = upload_from_directory(directory_path, dest_bucket_name, dest_blob_name)\";\n",
       "                var nbb_formatted_code = \"# trial\\nos.environ[\\\"GOOGLE_APPLICATION_CREDENTIALS\\\"] = str(GCS_token)\\n\\nstorage_client = storage.Client()\\n\\n\\ndef upload_from_directory(directory_path, dest_bucket_name, dest_blob_name):\\n    rel_paths = directory_path.glob(\\\"**/*\\\")\\n    bucket = storage_client.bucket(dest_bucket_name)\\n    for local_file in rel_paths:\\n        remote_path = f'{dest_blob_name}/{\\\"/\\\".join(str(local_file).split(os.sep)[5:])}'\\n        if os.path.isfile(local_file):\\n            blob = bucket.blob(remote_path)\\n            blob.upload_from_filename(local_file)\\n\\n    # print status\\n    print(\\\"Folder uploaded to GCS\\\")\\n\\n\\ndirectory_path = eessl_dir.joinpath(\\\"%s.zarr\\\" % eessl_out_file)\\ndest_bucket_name = \\\"dgds-data-public\\\"\\ndest_blob_name = \\\"coclico/\\\" + eessl_out_file + \\\".zarr\\\"\\nfolder_upload = upload_from_directory(directory_path, dest_bucket_name, dest_blob_name)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upload zarr folder to GCS\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = str(GCS_token)\n",
    "\n",
    "# function to upload zarr folder to GCS\n",
    "storage_client = storage.Client()\n",
    "def upload_from_directory(directory_path, dest_bucket_name, dest_blob_name):\n",
    "    rel_paths = directory_path.glob(\"**/*\")\n",
    "    bucket = storage_client.bucket(dest_bucket_name)\n",
    "    for local_file in rel_paths:\n",
    "        remote_path = f'{dest_blob_name}/{\"/\".join(str(local_file).split(os.sep)[5:])}' # note 5: is hardcoded and might lead to problems\n",
    "        if os.path.isfile(local_file):\n",
    "            blob = bucket.blob(remote_path)\n",
    "            blob.upload_from_filename(local_file)\n",
    "\n",
    "    # print status\n",
    "    print(\"Folder uploaded to GCS\")\n",
    "\n",
    "# specification of directory, bucket and file name to feed into the function\n",
    "directory_path = dataset_dir.joinpath(\"%s.zarr\" % dataset_out_file)\n",
    "dest_bucket_name = \"dgds-data-public\"\n",
    "dest_blob_name = \"coclico/\" + dataset_out_file + \".zarr\"\n",
    "folder_upload = upload_from_directory(directory_path, dest_bucket_name, dest_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2b32e",
   "metadata": {},
   "source": [
    "# 4. upload geoJSON to Mapbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59168879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"# ingest .geojson into mapbox tilesets\\n\\n# mapbox private acces key\\naccess_token = r\\\"sk.eyJ1IjoiZ2xvYmFsLWRhdGEtdmlld2VyIiwiYSI6ImNsMWx1azIyejA5cmwzanBueTNwdDB0djQifQ.hkbA5TGIiOcve4mZpi44Uw\\\"\\n\\n# python way of running CLI\\nfor idx, i in enumerate(ds_list_name):\\n    if len(i) > 32:\\n        out_name = ds_list_name[idx].replace(\\n            \\\"historical\\\", \\\"hist\\\"\\n        )  # cap is at 32 digits\\n    if len(i) < 32:\\n        out_name = i  # continue normally\\n\\n    # automated CLI mapbox upload\\n    subprocess.run(\\n        [\\n            \\\"mapbox\\\",\\n            \\\"--access-token\\\",\\n            access_token,\\n            \\\"upload\\\",\\n            r\\\"global-data-viewer.%s\\\" % out_name.split(\\\".\\\")[0],\\n            os.path.join(eessl_dir, \\\"platform\\\", r\\\"%s.geojson\\\" % i.split(\\\".\\\")[0]),\\n        ],\\n        shell=True,\\n        check=True,\\n    )\\n\\n# notebook version of CLI\\n#!mapbox --access-token {access_token} upload {filename} {source}\\n\\n# CLI command\\n# mapbox --access-token sk.eyJ1IjoiZ2xvYmFsLWRhdGEtdmlld2VyIiwiYSI6ImNsMWx1azIyejA5cmwzanBueTNwdDB0djQifQ.hkbA5TGIiOcve4mZpi44Uw upload global-data-viewer.test_cli_upload p:\\\\11205479-coclico\\\\data\\\\01_storm_surge_jrc\\\\platform\\\\CoastAlRisk_Europe_EESSL_Historical.geojson\";\n",
       "                var nbb_formatted_code = \"# ingest .geojson into mapbox tilesets\\n\\n# mapbox private acces key\\naccess_token = r\\\"sk.eyJ1IjoiZ2xvYmFsLWRhdGEtdmlld2VyIiwiYSI6ImNsMWx1azIyejA5cmwzanBueTNwdDB0djQifQ.hkbA5TGIiOcve4mZpi44Uw\\\"\\n\\n# python way of running CLI\\nfor idx, i in enumerate(ds_list_name):\\n    if len(i) > 32:\\n        out_name = ds_list_name[idx].replace(\\n            \\\"historical\\\", \\\"hist\\\"\\n        )  # cap is at 32 digits\\n    if len(i) < 32:\\n        out_name = i  # continue normally\\n\\n    # automated CLI mapbox upload\\n    subprocess.run(\\n        [\\n            \\\"mapbox\\\",\\n            \\\"--access-token\\\",\\n            access_token,\\n            \\\"upload\\\",\\n            r\\\"global-data-viewer.%s\\\" % out_name.split(\\\".\\\")[0],\\n            os.path.join(eessl_dir, \\\"platform\\\", r\\\"%s.geojson\\\" % i.split(\\\".\\\")[0]),\\n        ],\\n        shell=True,\\n        check=True,\\n    )\\n\\n# notebook version of CLI\\n#!mapbox --access-token {access_token} upload {filename} {source}\\n\\n# CLI command\\n# mapbox --access-token sk.eyJ1IjoiZ2xvYmFsLWRhdGEtdmlld2VyIiwiYSI6ImNsMWx1azIyejA5cmwzanBueTNwdDB0djQifQ.hkbA5TGIiOcve4mZpi44Uw upload global-data-viewer.test_cli_upload p:\\\\11205479-coclico\\\\data\\\\01_storm_surge_jrc\\\\platform\\\\CoastAlRisk_Europe_EESSL_Historical.geojson\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ingest geoJSON into mapbox tilesets\n",
    "\n",
    "# python way of running CLI\n",
    "for idx, i in enumerate(ds_list_name):\n",
    "    if len(i) > 32:\n",
    "        out_name = ds_list_name[idx].replace(\n",
    "            \"historical\", \"hist\"\n",
    "        )  # cap is at 32 digits\n",
    "    if len(i) < 32:\n",
    "        out_name = i  # continue normally\n",
    "\n",
    "    # automated CLI mapbox upload\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"mapbox\",\n",
    "            \"--access-token\",\n",
    "            mapbox_token,\n",
    "            \"upload\",\n",
    "            r\"global-data-viewer.%s\" % out_name.split(\".\")[0],\n",
    "            os.path.join(dataset_dir, \"platform\", r\"%s.geojson\" % i.split(\".\")[0]),\n",
    "        ],\n",
    "        shell=True,\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "# notebook version of CLI\n",
    "#!mapbox --access-token {mapbox_token} upload {filename} {source}\n",
    "\n",
    "# CLI command\n",
    "# mapbox --access-token sk.eyJ1IjoiZ2xvYmFsLWRhdGEtdmlld2VyIiwiYSI6ImNsMWx1azIyejA5cmwzanBueTNwdDB0djQifQ.hkbA5TGIiOcve4mZpi44Uw upload global-data-viewer.test_cli_upload p:\\11205479-coclico\\data\\01_storm_surge_jrc\\platform\\CoastAlRisk_Europe_EESSL_Historical.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e5bbd",
   "metadata": {},
   "source": [
    "# 5. Update the STAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb1893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
